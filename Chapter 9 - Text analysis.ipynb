{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 9: What we have covered so far (and a bit more)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter, we will work our way through a concise review of the Python functionality we have covered so far. Throughout this chapter, we will work with a interesting, yet not too large dataset, namely the well-known *Arabian nights*. *Alf Laylah Wa Laylah*, *the Stories of One Thousand and One Nights* is a collection of folk tales, collected over many centuries by various authors, translators, and scholars across West, Central and South Asia and North Africa, forms a huge narrative wheel with an overarching plot, created by the frame story of Shahrazad.\n",
    "\n",
    "The stories begin with the tale of king Shahryar and his brother, who, having both been deceived by their respective Sultanas, leave their kingdom, only to return when they have found someone who — in their view — was wronged even more. On their journey the two brothers encounter a huge jinn who carries a glass box containing a beautiful young woman. The two brothers hide as quickly as they can in a tree. The jinn lays his head on the girl’s lap and as soon as he is asleep, the girl demands the two kings to make love to her or else she will wake her ‘husband’. They reluctantly give in and the brothers soon discover that the girl has already betrayed the jinn ninety-eight times before. This exemplar of lust and treachery strengthens the Sultan’s opinion that all women are wicked and not to be trusted. \n",
    "\n",
    "When king Shahryar returns home, his wrath against women has grown to an unprecedented level. To temper his anger, each night the king sleeps with a virgin only to execute her the next morning. In order to make an end to this cruelty and save womanhood from a \"virgin scarcity\", Sharazad offers herself as the next king’s bride. On the first night, Sharazad begins to tell the king a story, but she does not end it. The king’s curiosity to know how the story ends, prevents him from executing Shahrazad. The next night Shahrazad finishes her story, and begins a new one. The king, eager to know the ending of this tale as well, postpones her execution once more. Using this strategy for One Thousand and One Nights in a labyrinth of stories-within-stories-within-stories, Shahrazad attempts to gradually move the king’s cynical stance against women towards a politics of love and justice (see Marina Warner’s *Stranger Magic* (2013) in case you're interested).\n",
    "\n",
    "The first European version of the Nights was translated into French by Antoine Galland. Many translations (in different languages) followed, such as the (heavily criticized) English translation by Sir Richard Francis Burton entitled *The Book of the Thousand and a Night* (1885). This version is freely available from the Gutenberg project (see [here](http://www.gutenberg.org)), and will be the one we will explore here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Files and directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the notebooks we use, there is a convenient way to quickly inspect the contents of a folder. Our Arabian nights are contained under the general `data``\n",
    " folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.txt     21.txt    322.txt   437.txt   55.txt    662.txt   775.txt   888.txt\r\n",
      "10.txt    210.txt   323.txt   438.txt   550.txt   663.txt   776.txt   889.txt\r\n",
      "100.txt   211.txt   324.txt   439.txt   551.txt   664.txt   777.txt   89.txt\r\n",
      "1000.txt  212.txt   325.txt   44.txt    552.txt   665.txt   778.txt   890.txt\r\n",
      "1001.txt  213.txt   326.txt   440.txt   553.txt   666.txt   779.txt   891.txt\r\n",
      "101.txt   214.txt   327.txt   441.txt   554.txt   667.txt   78.txt    892.txt\r\n",
      "102.txt   215.txt   328.txt   442.txt   555.txt   668.txt   780.txt   893.txt\r\n",
      "103.txt   216.txt   329.txt   443.txt   556.txt   669.txt   781.txt   894.txt\r\n",
      "104.txt   217.txt   33.txt    444.txt   557.txt   67.txt    782.txt   895.txt\r\n",
      "105.txt   218.txt   330.txt   445.txt   558.txt   670.txt   783.txt   896.txt\r\n",
      "106.txt   219.txt   331.txt   446.txt   559.txt   671.txt   784.txt   897.txt\r\n",
      "107.txt   22.txt    332.txt   447.txt   56.txt    672.txt   785.txt   898.txt\r\n",
      "108.txt   220.txt   333.txt   448.txt   560.txt   673.txt   786.txt   899.txt\r\n",
      "109.txt   221.txt   334.txt   449.txt   561.txt   674.txt   787.txt   9.txt\r\n",
      "11.txt    222.txt   335.txt   45.txt    562.txt   675.txt   788.txt   90.txt\r\n",
      "110.txt   223.txt   336.txt   450.txt   563.txt   676.txt   789.txt   900.txt\r\n",
      "111.txt   224.txt   337.txt   451.txt   564.txt   677.txt   79.txt    901.txt\r\n",
      "112.txt   225.txt   338.txt   452.txt   565.txt   678.txt   790.txt   902.txt\r\n",
      "113.txt   226.txt   339.txt   453.txt   566.txt   679.txt   791.txt   903.txt\r\n",
      "114.txt   227.txt   34.txt    454.txt   567.txt   68.txt    792.txt   904.txt\r\n",
      "115.txt   228.txt   340.txt   455.txt   568.txt   680.txt   793.txt   905.txt\r\n",
      "116.txt   229.txt   341.txt   456.txt   569.txt   681.txt   794.txt   906.txt\r\n",
      "117.txt   23.txt    342.txt   457.txt   57.txt    682.txt   795.txt   907.txt\r\n",
      "118.txt   230.txt   343.txt   458.txt   570.txt   683.txt   796.txt   908.txt\r\n",
      "119.txt   231.txt   344.txt   459.txt   571.txt   684.txt   797.txt   909.txt\r\n",
      "12.txt    232.txt   345.txt   46.txt    572.txt   685.txt   798.txt   91.txt\r",
      "\r\n",
      "120.txt   233.txt   346.txt   460.txt   573.txt   686.txt   799.txt   910.txt\r\n",
      "121.txt   234.txt   347.txt   461.txt   574.txt   687.txt   8.txt     911.txt\r\n",
      "122.txt   235.txt   348.txt   462.txt   575.txt   688.txt   80.txt    912.txt\r\n",
      "123.txt   236.txt   349.txt   463.txt   576.txt   689.txt   800.txt   913.txt\r\n",
      "124.txt   237.txt   35.txt    464.txt   577.txt   69.txt    801.txt   914.txt\r\n",
      "125.txt   238.txt   350.txt   465.txt   578.txt   690.txt   802.txt   915.txt\r\n",
      "126.txt   239.txt   351.txt   466.txt   579.txt   691.txt   803.txt   916.txt\r\n",
      "127.txt   24.txt    352.txt   467.txt   58.txt    692.txt   804.txt   917.txt\r\n",
      "128.txt   240.txt   353.txt   468.txt   580.txt   693.txt   805.txt   918.txt\r\n",
      "129.txt   241.txt   354.txt   469.txt   581.txt   694.txt   806.txt   919.txt\r\n",
      "13.txt    242.txt   355.txt   47.txt    582.txt   695.txt   807.txt   92.txt\r\n",
      "130.txt   243.txt   356.txt   470.txt   583.txt   696.txt   808.txt   920.txt\r\n",
      "131.txt   244.txt   357.txt   471.txt   584.txt   697.txt   809.txt   921.txt\r\n",
      "132.txt   245.txt   358.txt   472.txt   585.txt   698.txt   81.txt    922.txt\r\n",
      "133.txt   246.txt   359.txt   473.txt   586.txt   699.txt   810.txt   923.txt\r\n",
      "134.txt   247.txt   36.txt    474.txt   587.txt   7.txt     811.txt   924.txt\r\n",
      "135.txt   248.txt   360.txt   475.txt   588.txt   70.txt    812.txt   925.txt\r\n",
      "136.txt   249.txt   361.txt   476.txt   589.txt   700.txt   813.txt   926.txt\r\n",
      "137.txt   25.txt    362.txt   477.txt   59.txt    701.txt   814.txt   927.txt\r\n",
      "138.txt   250.txt   363.txt   478.txt   590.txt   702.txt   815.txt   928.txt\r\n",
      "139.txt   251.txt   364.txt   479.txt   591.txt   703.txt   816.txt   929.txt\r\n",
      "14.txt    252.txt   365.txt   48.txt    592.txt   704.txt   817.txt   93.txt\r\n",
      "140.txt   253.txt   366.txt   480.txt   593.txt   705.txt   818.txt   930.txt\r\n",
      "141.txt   254.txt   367.txt   481.txt   594.txt   706.txt   819.txt   931.txt\r\n",
      "142.txt   255.txt   368.txt   482.txt   595.txt   707.txt   82.txt    932.txt\r\n",
      "143.txt   256.txt   369.txt   483.txt   596.txt   708.txt   820.txt   933.txt\r\n",
      "144.txt   257.txt   37.txt    484.txt   597.txt   709.txt   821.txt   934.txt\r\n",
      "145.txt   258.txt   370.txt   485.txt   598.txt   71.txt    822.txt   935.txt\r\n",
      "146.txt   259.txt   371.txt   486.txt   599.txt   710.txt   823.txt   936.txt\r\n",
      "147.txt   26.txt    372.txt   487.txt   6.txt     711.txt   824.txt   937.txt\r\n",
      "148.txt   260.txt   373.txt   488.txt   60.txt    712.txt   825.txt   938.txt\r\n",
      "149.txt   261.txt   374.txt   489.txt   600.txt   713.txt   826.txt   939.txt\r\n",
      "15.txt    262.txt   375.txt   49.txt    601.txt   714.txt   827.txt   94.txt\r\n",
      "150.txt   263.txt   376.txt   490.txt   602.txt   715.txt   828.txt   940.txt\r\n",
      "151.txt   264.txt   377.txt   491.txt   603.txt   716.txt   829.txt   941.txt\r\n",
      "152.txt   265.txt   378.txt   492.txt   604.txt   717.txt   83.txt    942.txt\r\n",
      "153.txt   266.txt   379.txt   493.txt   605.txt   718.txt   830.txt   943.txt\r\n",
      "154.txt   267.txt   38.txt    494.txt   606.txt   719.txt   831.txt   944.txt\r\n",
      "155.txt   268.txt   380.txt   495.txt   607.txt   72.txt    832.txt   945.txt\r\n",
      "156.txt   269.txt   381.txt   496.txt   608.txt   720.txt   833.txt   946.txt\r\n",
      "157.txt   27.txt    382.txt   497.txt   609.txt   721.txt   834.txt   947.txt\r\n",
      "158.txt   270.txt   383.txt   498.txt   61.txt    722.txt   835.txt   948.txt\r\n",
      "159.txt   271.txt   384.txt   499.txt   610.txt   723.txt   836.txt   949.txt\r\n",
      "16.txt    272.txt   385.txt   5.txt     611.txt   724.txt   837.txt   95.txt\r\n",
      "160.txt   273.txt   386.txt   50.txt    612.txt   725.txt   838.txt   950.txt\r\n",
      "161.txt   274.txt   387.txt   500.txt   613.txt   726.txt   839.txt   951.txt\r\n",
      "162.txt   275.txt   388.txt   501.txt   614.txt   727.txt   84.txt    952.txt\r\n",
      "163.txt   276.txt   389.txt   502.txt   615.txt   728.txt   840.txt   953.txt\r\n",
      "164.txt   277.txt   39.txt    503.txt   616.txt   729.txt   841.txt   954.txt\r\n",
      "165.txt   278.txt   390.txt   504.txt   617.txt   73.txt    842.txt   955.txt\r\n",
      "166.txt   279.txt   391.txt   505.txt   618.txt   730.txt   843.txt   956.txt\r\n",
      "167.txt   28.txt    392.txt   506.txt   619.txt   731.txt   844.txt   957.txt\r\n",
      "168.txt   280.txt   393.txt   507.txt   62.txt    732.txt   845.txt   958.txt\r\n",
      "169.txt   281.txt   394.txt   508.txt   620.txt   733.txt   846.txt   959.txt\r\n",
      "17.txt    282.txt   395.txt   509.txt   621.txt   734.txt   847.txt   96.txt\r\n",
      "170.txt   283.txt   398.txt   51.txt    622.txt   735.txt   848.txt   960.txt\r\n",
      "171.txt   284.txt   399.txt   510.txt   623.txt   736.txt   849.txt   961.txt\r\n",
      "172.txt   285.txt   4.txt     511.txt   624.txt   737.txt   85.txt    962.txt\r\n",
      "173.txt   286.txt   40.txt    512.txt   625.txt   738.txt   850.txt   963.txt\r\n",
      "174.txt   287.txt   400.txt   513.txt   626.txt   739.txt   851.txt   964.txt\r\n",
      "175.txt   288.txt   401.txt   514.txt   627.txt   74.txt    852.txt   965.txt\r\n",
      "176.txt   289.txt   402.txt   515.txt   628.txt   740.txt   853.txt   966.txt\r\n",
      "177.txt   29.txt    403.txt   516.txt   629.txt   741.txt   854.txt   967.txt\r\n",
      "178.txt   290.txt   404.txt   517.txt   63.txt    742.txt   855.txt   968.txt\r\n",
      "179.txt   291.txt   405.txt   518.txt   630.txt   743.txt   856.txt   969.txt\r\n",
      "18.txt    292.txt   406.txt   519.txt   631.txt   744.txt   857.txt   97.txt\r\n",
      "180.txt   293.txt   407.txt   52.txt    632.txt   745.txt   858.txt   970.txt\r\n",
      "181.txt   294.txt   408.txt   520.txt   633.txt   746.txt   859.txt   971.txt\r\n",
      "182.txt   295.txt   409.txt   521.txt   634.txt   747.txt   86.txt    972.txt\r\n",
      "183.txt   296.txt   41.txt    522.txt   635.txt   748.txt   860.txt   973.txt\r\n",
      "184.txt   297.txt   410.txt   523.txt   636.txt   749.txt   861.txt   974.txt\r\n",
      "185.txt   298.txt   411.txt   524.txt   637.txt   75.txt    862.txt   975.txt\r\n",
      "186.txt   299.txt   412.txt   525.txt   638.txt   750.txt   863.txt   976.txt\r\n",
      "187.txt   3.txt     413.txt   526.txt   639.txt   751.txt   864.txt   977.txt\r\n",
      "188.txt   30.txt    414.txt   527.txt   64.txt    752.txt   865.txt   978.txt\r\n",
      "189.txt   300.txt   415.txt   528.txt   640.txt   753.txt   866.txt   979.txt\r\n",
      "19.txt    301.txt   416.txt   529.txt   641.txt   754.txt   867.txt   98.txt\r\n",
      "190.txt   302.txt   417.txt   53.txt    642.txt   755.txt   868.txt   980.txt\r\n",
      "191.txt   303.txt   418.txt   530.txt   643.txt   756.txt   869.txt   981.txt\r\n",
      "192.txt   304.txt   419.txt   531.txt   644.txt   757.txt   87.txt    982.txt\r\n",
      "193.txt   305.txt   42.txt    532.txt   645.txt   758.txt   870.txt   983.txt\r\n",
      "194.txt   306.txt   420.txt   533.txt   646.txt   759.txt   871.txt   984.txt\r\n",
      "195.txt   307.txt   421.txt   534.txt   647.txt   76.txt    872.txt   985.txt\r\n",
      "196.txt   308.txt   422.txt   535.txt   648.txt   760.txt   873.txt   986.txt\r\n",
      "197.txt   309.txt   423.txt   536.txt   649.txt   761.txt   874.txt   987.txt\r\n",
      "198.txt   31.txt    424.txt   537.txt   65.txt    762.txt   875.txt   988.txt\r\n",
      "199.txt   310.txt   425.txt   538.txt   650.txt   763.txt   876.txt   989.txt\r\n",
      "2.txt     311.txt   426.txt   539.txt   651.txt   764.txt   877.txt   99.txt\r\n",
      "20.txt    312.txt   427.txt   54.txt    652.txt   765.txt   878.txt   990.txt\r\n",
      "200.txt   313.txt   428.txt   540.txt   653.txt   766.txt   879.txt   991.txt\r\n",
      "201.txt   314.txt   429.txt   541.txt   654.txt   767.txt   88.txt    992.txt\r\n",
      "202.txt   315.txt   43.txt    542.txt   655.txt   768.txt   880.txt   993.txt\r\n",
      "203.txt   316.txt   430.txt   543.txt   656.txt   769.txt   881.txt   994.txt\r\n",
      "204.txt   317.txt   431.txt   544.txt   657.txt   77.txt    882.txt   995.txt\r\n",
      "205.txt   318.txt   432.txt   545.txt   658.txt   770.txt   883.txt   996.txt\r\n",
      "206.txt   319.txt   433.txt   546.txt   659.txt   771.txt   884.txt   997.txt\r\n",
      "207.txt   32.txt    434.txt   547.txt   66.txt    772.txt   885.txt   998.txt\r\n",
      "208.txt   320.txt   435.txt   548.txt   660.txt   773.txt   886.txt   999.txt\r\n",
      "209.txt   321.txt   436.txt   549.txt   661.txt   774.txt   887.txt\r\n"
     ]
    }
   ],
   "source": [
    "ls data/arabian_nights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this folder holds a number of plain text files, ending in the `.txt` extension. Let us open a random file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",\n",
      "She pursued, It hath reached me, O auspicious King, that when Zayn al-Mawasif took from the Kazi the deed which made over her lover's property to her, she said to him, \"O Masrur, now gang thy gait.\" But her slave-girl Hubub turned to him and said, \"Recite us some verses.\" So he improvised upon that game of chess these couplets,\n",
      "\"Of Time and what befel me I complain, * Mourning my loss by chess and eyes of bane.  \n",
      " For love of gentlest, softest-sided fair * Whose like is not of maids or mortal \n"
     ]
    }
   ],
   "source": [
    "f = open('data/arabian_nights/848.txt', 'r')\n",
    "text = f.read()\n",
    "f.close()\n",
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use the `open()` function to create a file object `f`, which we can use to access the actual text content of the file. Make sure that you do not pass the `'w'` parameter (\"write\") to `open()`, instead of `'r'`, since this would overwrite and thus erase the existing file.  After assigning the string returned by `f.read()` to the variable `text`, we print the 500 first characters of `text` to get an impression of what it contains, using simple string indexing (`[:500]`). Don't forget to close the file again after you have opened or strange things could happen to your file! One little trick which is commonly used to avoid having to explicitly opening and closing your file is a `with` block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",\n",
      "She pursued, It hath reached me, O auspicious King, that when Zayn al-Mawasif took from the Kazi the deed which made over her lover's property to her, she said to him, \"O Masrur, now gang thy gait.\" But her slave-girl Hubub turned to him and said, \"Recite us some verses.\" So he improvised upon that game of chess these couplets,\n",
      "\"Of Time and what befel me I complain, * Mourning my loss by chess and eyes of bane.  \n",
      " For love of gentlest, softest-sided fair * Whose like is not of maids or mortal \n"
     ]
    }
   ],
   "source": [
    "with open('data/arabian_nights/848.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block does exactly the same thing as the previous one but saves you some typing. In this chapter we would like to work with all the files in the `arabian_nights` directory. This is where loops come in handy of course, since what we really would like to do, is iterate over the contents of the directory. Accessing these contents in Python is easy, but requires importing some extra functionality. In this case, we need to import the `os` module, which contains all functionality related to the 'operating system' of your machine, such as directory information:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the dot-syntax (`os.xxx`), we can now access all functions that come with this module, such as `listdir()`, which returns a list of the items which are included under a given directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999\n",
      "['1.txt', '10.txt', '100.txt', '1000.txt', '1001.txt', '101.txt', '102.txt', '103.txt', '104.txt', '105.txt', '106.txt', '107.txt', '108.txt', '109.txt', '11.txt', '110.txt', '111.txt', '112.txt', '113.txt', '114.txt']\n"
     ]
    }
   ],
   "source": [
    "filenames = os.listdir('data/arabian_nights')\n",
    "print(len(filenames))\n",
    "print(filenames[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `os.listdir()` returns a list of strings, representing the filenames contained under a directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz\n",
    "\n",
    "1. In Burton's translation some of the 1001 nights are missing. How many?\n",
    "2. Can you come up with a clever way to find out which nights are missing? Hint: a counting loop and some string casting might be useful here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `os.listdir()`, you need to make sure that you pass the correct path to an existing directory:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/belgian_nights'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-9628c8703de0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/belgian_nights'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/belgian_nights'"
     ]
    }
   ],
   "source": [
    "os.listdir('data/belgian_nights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It might therefore be convenient to check whether a directory actually exists in a given location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(os.path.isdir('data/arabian_nights'))\n",
    "print(os.path.isdir('data/belgian_nights'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second directory, naturally, does not exist and `isdir()` evaluates to `False` in this case. Creating a new (and thus empty) directory is also easy using `os`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.mkdir('belgian_nights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that it lives in the present working directory now, by typing `ls` agian:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mChapter 1 - Variables.ipynb\u001b[m\u001b[m*           README.md\r\n",
      "\u001b[31mChapter 2 - Collections.ipynb\u001b[m\u001b[m*         \u001b[34massignment\u001b[m\u001b[m/\r\n",
      "\u001b[31mChapter 3 - Conditions.ipynb\u001b[m\u001b[m*          \u001b[34mbelgian_nights\u001b[m\u001b[m/\r\n",
      "\u001b[31mChapter 4 - Loops.ipynb\u001b[m\u001b[m*               \u001b[34mdata\u001b[m\u001b[m/\r\n",
      "\u001b[31mChapter 5 - Functions and Files.ipynb\u001b[m\u001b[m* \u001b[34mexercise_keys\u001b[m\u001b[m/\r\n",
      "Chapter 6 - Regular Expressions.ipynb  \u001b[34mimages\u001b[m\u001b[m/\r\n",
      "Chapter 7 - More on Loops.ipynb        \u001b[31mstart-osx.command\u001b[m\u001b[m*\r\n",
      "Chapter 8 - Parsing XML.ipynb          \u001b[31mstart-unix.sh\u001b[m\u001b[m*\r\n",
      "Chapter x - Text analysis.ipynb        \u001b[31mstart-windows.bat\u001b[m\u001b[m*\r\n",
      "LICENSE                                \u001b[34mstyles\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we use Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(os.path.isdir('belgian_nights'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing directories is also easy, but PLEASE watch out, sometimes is is too easy: if you remove a wrong directory in Python, it will be gone forever... Unlike other applications, Python does not keep a copy of it in your Trash and it does not have a Ctrl-Z button. Please watch out with what you do, since with great power comes great responsiblity! Removing the entire directory which we just created can be done as follows:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree('belgian_nights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And lo behold: the directory has disappeared again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(os.path.isdir('belgian_nights'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use the `rmtree()` command to remove the entire directory in a *recursive* way: even if the directory isn't empty and contains files and subfolers, we will remove all of them. The `os` module also comes with a `rmdir()` but this will not allow you to remove a directory which is not empty, as becomes clear in the `OSError` raised below:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 66] Directory not empty: 'data/arabian_nights'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-966b57c5f1cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/arabian_nights'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m: [Errno 66] Directory not empty: 'data/arabian_nights'"
     ]
    }
   ],
   "source": [
    "os.rmdir('data/arabian_nights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The folder contains things and therefore cannot be removed using this function. There are, of course, also ways to remove individual files or check whether they exist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "os.mkdir('belgian_nights')\n",
    "f = open('belgian_nights/1001.txt', 'w')\n",
    "f.write('Content')\n",
    "f.close()\n",
    "print(os.path.exists('belgian_nights/1001.txt'))\n",
    "os.remove('belgian_nights/1001.txt')\n",
    "print(os.path.exists('belgian_nights/1001.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we create a directory, write a new file to it (`1001.txt`), and removed it again. Using `os.path.exists()` we monitored at which point the file existed. Finally, the `shutil` module also ships with a useful `copyfile()` function which allows you to copy files from one location to another, possible with another name. To copy night 66 to the present directory, for instance, we could do: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'new_66.txt'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.copyfile('data/arabian_nights/66.txt', 'new_66.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, we have added an exact copy of night 66 to our present working directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mChapter 1 - Variables.ipynb\u001b[m\u001b[m*           \u001b[34massignment\u001b[m\u001b[m/\r\n",
      "\u001b[31mChapter 2 - Collections.ipynb\u001b[m\u001b[m*         \u001b[34mbelgian_nights\u001b[m\u001b[m/\r\n",
      "\u001b[31mChapter 3 - Conditions.ipynb\u001b[m\u001b[m*          \u001b[34mdata\u001b[m\u001b[m/\r\n",
      "\u001b[31mChapter 4 - Loops.ipynb\u001b[m\u001b[m*               \u001b[34mexercise_keys\u001b[m\u001b[m/\r\n",
      "\u001b[31mChapter 5 - Functions and Files.ipynb\u001b[m\u001b[m* \u001b[34mimages\u001b[m\u001b[m/\r\n",
      "Chapter 6 - Regular Expressions.ipynb  new_66.txt\r\n",
      "Chapter 7 - More on Loops.ipynb        \u001b[31mstart-osx.command\u001b[m\u001b[m*\r\n",
      "Chapter 8 - Parsing XML.ipynb          \u001b[31mstart-unix.sh\u001b[m\u001b[m*\r\n",
      "Chapter x - Text analysis.ipynb        \u001b[31mstart-windows.bat\u001b[m\u001b[m*\r\n",
      "LICENSE                                \u001b[34mstyles\u001b[m\u001b[m/\r\n",
      "README.md\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can safely remove it again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.remove('new_66.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paths we have used so far are 'relative' paths, in the sense that they are relative to the place on our machine from which we execute our Python code. Absolute paths can also be retrieved and will differ on each computer, because they typically include user names etc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mike/GitRepos/ghent1516/data/arabian_nights/848.txt'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.abspath('data/arabian_nights/848.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While absolute paths are longer to type, they have the advantage that they can be used anywhere on your computer (i.e. irrespective of where you run your code from). Paths can be tricky. Suppose that we would like to open one of our filenames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '105.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-157-a41ea4677219>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/arabian_nights'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrnd_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnd_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '105.txt'"
     ]
    }
   ],
   "source": [
    "filenames = os.listdir('data/arabian_nights')\n",
    "rnd_filename = filenames[9]\n",
    "with open(rnd_filename, 'r') as f:\n",
    "    text = f.read()\n",
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python throws a `FileNotFoundError`, complaining that the file we wish to open does not exist. This situation stems from the fact that `os.listdir()` only returns the basic name of a given file, and not an entire (absolute or relative) path to it. To properly access the file, we must therefore not forget to include the rest of the path again: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",\n",
      "She said, It hath reached me, O auspicious King, that they laid Sharrkan out and buried him in the mountain aforesaid and mourned over his far-famed virtues. Then they looked for the opening of the city gate; but it opened not and no sign of men appeared to them on the walls; whereat they wondered with exceeding wonder. But King Zau al-Makan said, \"By Allah, I will not turn back from them, though I sit here for years and years, till I take blood revenge for my brother Sharrkan and waste Consta\n"
     ]
    }
   ],
   "source": [
    "filenames = os.listdir('data/arabian_nights')\n",
    "rnd_filename = filenames[9]\n",
    "with open('data/arabian_nights/'+rnd_filename, 'r') as f:\n",
    "    text = f.read()\n",
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from `os.listdir()` there are a number of other common to obtain directory listings in Python. Using the `glob` module for instance, we can easily access the full relative path leading to our Arabian Nights:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/arabian_nights/1.txt', 'data/arabian_nights/10.txt', 'data/arabian_nights/100.txt', 'data/arabian_nights/1000.txt', 'data/arabian_nights/1001.txt', 'data/arabian_nights/101.txt', 'data/arabian_nights/102.txt', 'data/arabian_nights/103.txt', 'data/arabian_nights/104.txt', 'data/arabian_nights/105.txt']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "filenames = glob.glob('data/arabian_nights/*')\n",
    "print(filenames[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The asterisk (`*`) in the argument passed to `glob.glob()` is worth noting here. Just like with regular expressions, this asterisk is a sort of wildcard which will match any series of characters (i.e. the filenames under `arabian_nights`). When we exploit this wildcard syntax, `glob.glob()` offers another distinct advantage: we can use it to easily filter out filenames which we are not interested in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/arabian_nights/1.txt', 'data/arabian_nights/10.txt', 'data/arabian_nights/100.txt', 'data/arabian_nights/1000.txt', 'data/arabian_nights/1001.txt', 'data/arabian_nights/101.txt', 'data/arabian_nights/102.txt', 'data/arabian_nights/103.txt', 'data/arabian_nights/104.txt', 'data/arabian_nights/105.txt']\n"
     ]
    }
   ],
   "source": [
    "filenames = glob.glob('data/arabian_nights/*.txt')\n",
    "print(filenames[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the command in this code block will only load filenames that end in `\".txt\"`. This is interesting when we would like to ignore other sort of junk files etc. that might be present in a directory. To replicate similar behaviour with `os.listdir()`, we would have needed a typical `for`-loop, such as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.txt', '10.txt', '100.txt', '1000.txt', '1001.txt', '101.txt', '102.txt', '103.txt', '104.txt', '105.txt']\n"
     ]
    }
   ],
   "source": [
    "filenames = []\n",
    "for fn in os.listdir('data/arabian_nights'):\n",
    "    if fn.endswith('.txt'):\n",
    "        filenames.append(fn)\n",
    "print(filenames[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or for you stylish coders out there, with a list comprehension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames = [fn for fn in os.listdir('data/arabian_nights') if fn.endswith('.txt')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, when using `glob.glob()`, you might sometimes want to be able to extract a file's base name again. There are several solutions to this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106.txt\n",
      "106.txt\n",
      "106.txt\n"
     ]
    }
   ],
   "source": [
    "filenames = glob.glob('data/arabian_nights/*.txt')\n",
    "fn = filenames[10]\n",
    "\n",
    "# simple string splittng:\n",
    "print(fn.split('/')[-1])\n",
    "\n",
    "# using os.sep:\n",
    "print(fn.split(os.sep)[-1])\n",
    "\n",
    "# using os.path:\n",
    "print(os.path.basename(fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, sometimes, you might be interested in all the subdirectories of a particular directory (and all the subdirectories of these subdirectories etc.). Parsing such deep directory structures, can be tricky, especially if you do not know how deep a directory tree might run. You could of course try stacking multiple loops using `os.listdir()`, but a more convenient way is `os.walk()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'austen-emma-excerpt-tokenised.txt', 'austen-emma-excerpt.txt', 'austen-emma.txt', 'words.txt']\n",
      "['1.txt', '10.txt', '100.txt', '1000.txt', '1001.txt', '101.txt', '102.txt', '103.txt', '104.txt', '105.txt', '106.txt', '107.txt', '108.txt', '109.txt', '11.txt', '110.txt', '111.txt', '112.txt', '113.txt', '114.txt', '115.txt', '116.txt', '117.txt', '118.txt', '119.txt', '12.txt', '120.txt', '121.txt', '122.txt', '123.txt', '124.txt', '125.txt', '126.txt', '127.txt', '128.txt', '129.txt', '13.txt', '130.txt', '131.txt', '132.txt', '133.txt', '134.txt', '135.txt', '136.txt', '137.txt', '138.txt', '139.txt', '14.txt', '140.txt', '141.txt', '142.txt', '143.txt', '144.txt', '145.txt', '146.txt', '147.txt', '148.txt', '149.txt', '15.txt', '150.txt', '151.txt', '152.txt', '153.txt', '154.txt', '155.txt', '156.txt', '157.txt', '158.txt', '159.txt', '16.txt', '160.txt', '161.txt', '162.txt', '163.txt', '164.txt', '165.txt', '166.txt', '167.txt', '168.txt', '169.txt', '17.txt', '170.txt', '171.txt', '172.txt', '173.txt', '174.txt', '175.txt', '176.txt', '177.txt', '178.txt', '179.txt', '18.txt', '180.txt', '181.txt', '182.txt', '183.txt', '184.txt', '185.txt', '186.txt', '187.txt', '188.txt', '189.txt', '19.txt', '190.txt', '191.txt', '192.txt', '193.txt', '194.txt', '195.txt', '196.txt', '197.txt', '198.txt', '199.txt', '2.txt', '20.txt', '200.txt', '201.txt', '202.txt', '203.txt', '204.txt', '205.txt', '206.txt', '207.txt', '208.txt', '209.txt', '21.txt', '210.txt', '211.txt', '212.txt', '213.txt', '214.txt', '215.txt', '216.txt', '217.txt', '218.txt', '219.txt', '22.txt', '220.txt', '221.txt', '222.txt', '223.txt', '224.txt', '225.txt', '226.txt', '227.txt', '228.txt', '229.txt', '23.txt', '230.txt', '231.txt', '232.txt', '233.txt', '234.txt', '235.txt', '236.txt', '237.txt', '238.txt', '239.txt', '24.txt', '240.txt', '241.txt', '242.txt', '243.txt', '244.txt', '245.txt', '246.txt', '247.txt', '248.txt', '249.txt', '25.txt', '250.txt', '251.txt', '252.txt', '253.txt', '254.txt', '255.txt', '256.txt', '257.txt', '258.txt', '259.txt', '26.txt', '260.txt', '261.txt', '262.txt', '263.txt', '264.txt', '265.txt', '266.txt', '267.txt', '268.txt', '269.txt', '27.txt', '270.txt', '271.txt', '272.txt', '273.txt', '274.txt', '275.txt', '276.txt', '277.txt', '278.txt', '279.txt', '28.txt', '280.txt', '281.txt', '282.txt', '283.txt', '284.txt', '285.txt', '286.txt', '287.txt', '288.txt', '289.txt', '29.txt', '290.txt', '291.txt', '292.txt', '293.txt', '294.txt', '295.txt', '296.txt', '297.txt', '298.txt', '299.txt', '3.txt', '30.txt', '300.txt', '301.txt', '302.txt', '303.txt', '304.txt', '305.txt', '306.txt', '307.txt', '308.txt', '309.txt', '31.txt', '310.txt', '311.txt', '312.txt', '313.txt', '314.txt', '315.txt', '316.txt', '317.txt', '318.txt', '319.txt', '32.txt', '320.txt', '321.txt', '322.txt', '323.txt', '324.txt', '325.txt', '326.txt', '327.txt', '328.txt', '329.txt', '33.txt', '330.txt', '331.txt', '332.txt', '333.txt', '334.txt', '335.txt', '336.txt', '337.txt', '338.txt', '339.txt', '34.txt', '340.txt', '341.txt', '342.txt', '343.txt', '344.txt', '345.txt', '346.txt', '347.txt', '348.txt', '349.txt', '35.txt', '350.txt', '351.txt', '352.txt', '353.txt', '354.txt', '355.txt', '356.txt', '357.txt', '358.txt', '359.txt', '36.txt', '360.txt', '361.txt', '362.txt', '363.txt', '364.txt', '365.txt', '366.txt', '367.txt', '368.txt', '369.txt', '37.txt', '370.txt', '371.txt', '372.txt', '373.txt', '374.txt', '375.txt', '376.txt', '377.txt', '378.txt', '379.txt', '38.txt', '380.txt', '381.txt', '382.txt', '383.txt', '384.txt', '385.txt', '386.txt', '387.txt', '388.txt', '389.txt', '39.txt', '390.txt', '391.txt', '392.txt', '393.txt', '394.txt', '395.txt', '398.txt', '399.txt', '4.txt', '40.txt', '400.txt', '401.txt', '402.txt', '403.txt', '404.txt', '405.txt', '406.txt', '407.txt', '408.txt', '409.txt', '41.txt', '410.txt', '411.txt', '412.txt', '413.txt', '414.txt', '415.txt', '416.txt', '417.txt', '418.txt', '419.txt', '42.txt', '420.txt', '421.txt', '422.txt', '423.txt', '424.txt', '425.txt', '426.txt', '427.txt', '428.txt', '429.txt', '43.txt', '430.txt', '431.txt', '432.txt', '433.txt', '434.txt', '435.txt', '436.txt', '437.txt', '438.txt', '439.txt', '44.txt', '440.txt', '441.txt', '442.txt', '443.txt', '444.txt', '445.txt', '446.txt', '447.txt', '448.txt', '449.txt', '45.txt', '450.txt', '451.txt', '452.txt', '453.txt', '454.txt', '455.txt', '456.txt', '457.txt', '458.txt', '459.txt', '46.txt', '460.txt', '461.txt', '462.txt', '463.txt', '464.txt', '465.txt', '466.txt', '467.txt', '468.txt', '469.txt', '47.txt', '470.txt', '471.txt', '472.txt', '473.txt', '474.txt', '475.txt', '476.txt', '477.txt', '478.txt', '479.txt', '48.txt', '480.txt', '481.txt', '482.txt', '483.txt', '484.txt', '485.txt', '486.txt', '487.txt', '488.txt', '489.txt', '49.txt', '490.txt', '491.txt', '492.txt', '493.txt', '494.txt', '495.txt', '496.txt', '497.txt', '498.txt', '499.txt', '5.txt', '50.txt', '500.txt', '501.txt', '502.txt', '503.txt', '504.txt', '505.txt', '506.txt', '507.txt', '508.txt', '509.txt', '51.txt', '510.txt', '511.txt', '512.txt', '513.txt', '514.txt', '515.txt', '516.txt', '517.txt', '518.txt', '519.txt', '52.txt', '520.txt', '521.txt', '522.txt', '523.txt', '524.txt', '525.txt', '526.txt', '527.txt', '528.txt', '529.txt', '53.txt', '530.txt', '531.txt', '532.txt', '533.txt', '534.txt', '535.txt', '536.txt', '537.txt', '538.txt', '539.txt', '54.txt', '540.txt', '541.txt', '542.txt', '543.txt', '544.txt', '545.txt', '546.txt', '547.txt', '548.txt', '549.txt', '55.txt', '550.txt', '551.txt', '552.txt', '553.txt', '554.txt', '555.txt', '556.txt', '557.txt', '558.txt', '559.txt', '56.txt', '560.txt', '561.txt', '562.txt', '563.txt', '564.txt', '565.txt', '566.txt', '567.txt', '568.txt', '569.txt', '57.txt', '570.txt', '571.txt', '572.txt', '573.txt', '574.txt', '575.txt', '576.txt', '577.txt', '578.txt', '579.txt', '58.txt', '580.txt', '581.txt', '582.txt', '583.txt', '584.txt', '585.txt', '586.txt', '587.txt', '588.txt', '589.txt', '59.txt', '590.txt', '591.txt', '592.txt', '593.txt', '594.txt', '595.txt', '596.txt', '597.txt', '598.txt', '599.txt', '6.txt', '60.txt', '600.txt', '601.txt', '602.txt', '603.txt', '604.txt', '605.txt', '606.txt', '607.txt', '608.txt', '609.txt', '61.txt', '610.txt', '611.txt', '612.txt', '613.txt', '614.txt', '615.txt', '616.txt', '617.txt', '618.txt', '619.txt', '62.txt', '620.txt', '621.txt', '622.txt', '623.txt', '624.txt', '625.txt', '626.txt', '627.txt', '628.txt', '629.txt', '63.txt', '630.txt', '631.txt', '632.txt', '633.txt', '634.txt', '635.txt', '636.txt', '637.txt', '638.txt', '639.txt', '64.txt', '640.txt', '641.txt', '642.txt', '643.txt', '644.txt', '645.txt', '646.txt', '647.txt', '648.txt', '649.txt', '65.txt', '650.txt', '651.txt', '652.txt', '653.txt', '654.txt', '655.txt', '656.txt', '657.txt', '658.txt', '659.txt', '66.txt', '660.txt', '661.txt', '662.txt', '663.txt', '664.txt', '665.txt', '666.txt', '667.txt', '668.txt', '669.txt', '67.txt', '670.txt', '671.txt', '672.txt', '673.txt', '674.txt', '675.txt', '676.txt', '677.txt', '678.txt', '679.txt', '68.txt', '680.txt', '681.txt', '682.txt', '683.txt', '684.txt', '685.txt', '686.txt', '687.txt', '688.txt', '689.txt', '69.txt', '690.txt', '691.txt', '692.txt', '693.txt', '694.txt', '695.txt', '696.txt', '697.txt', '698.txt', '699.txt', '7.txt', '70.txt', '700.txt', '701.txt', '702.txt', '703.txt', '704.txt', '705.txt', '706.txt', '707.txt', '708.txt', '709.txt', '71.txt', '710.txt', '711.txt', '712.txt', '713.txt', '714.txt', '715.txt', '716.txt', '717.txt', '718.txt', '719.txt', '72.txt', '720.txt', '721.txt', '722.txt', '723.txt', '724.txt', '725.txt', '726.txt', '727.txt', '728.txt', '729.txt', '73.txt', '730.txt', '731.txt', '732.txt', '733.txt', '734.txt', '735.txt', '736.txt', '737.txt', '738.txt', '739.txt', '74.txt', '740.txt', '741.txt', '742.txt', '743.txt', '744.txt', '745.txt', '746.txt', '747.txt', '748.txt', '749.txt', '75.txt', '750.txt', '751.txt', '752.txt', '753.txt', '754.txt', '755.txt', '756.txt', '757.txt', '758.txt', '759.txt', '76.txt', '760.txt', '761.txt', '762.txt', '763.txt', '764.txt', '765.txt', '766.txt', '767.txt', '768.txt', '769.txt', '77.txt', '770.txt', '771.txt', '772.txt', '773.txt', '774.txt', '775.txt', '776.txt', '777.txt', '778.txt', '779.txt', '78.txt', '780.txt', '781.txt', '782.txt', '783.txt', '784.txt', '785.txt', '786.txt', '787.txt', '788.txt', '789.txt', '79.txt', '790.txt', '791.txt', '792.txt', '793.txt', '794.txt', '795.txt', '796.txt', '797.txt', '798.txt', '799.txt', '8.txt', '80.txt', '800.txt', '801.txt', '802.txt', '803.txt', '804.txt', '805.txt', '806.txt', '807.txt', '808.txt', '809.txt', '81.txt', '810.txt', '811.txt', '812.txt', '813.txt', '814.txt', '815.txt', '816.txt', '817.txt', '818.txt', '819.txt', '82.txt', '820.txt', '821.txt', '822.txt', '823.txt', '824.txt', '825.txt', '826.txt', '827.txt', '828.txt', '829.txt', '83.txt', '830.txt', '831.txt', '832.txt', '833.txt', '834.txt', '835.txt', '836.txt', '837.txt', '838.txt', '839.txt', '84.txt', '840.txt', '841.txt', '842.txt', '843.txt', '844.txt', '845.txt', '846.txt', '847.txt', '848.txt', '849.txt', '85.txt', '850.txt', '851.txt', '852.txt', '853.txt', '854.txt', '855.txt', '856.txt', '857.txt', '858.txt', '859.txt', '86.txt', '860.txt', '861.txt', '862.txt', '863.txt', '864.txt', '865.txt', '866.txt', '867.txt', '868.txt', '869.txt', '87.txt', '870.txt', '871.txt', '872.txt', '873.txt', '874.txt', '875.txt', '876.txt', '877.txt', '878.txt', '879.txt', '88.txt', '880.txt', '881.txt', '882.txt', '883.txt', '884.txt', '885.txt', '886.txt', '887.txt', '888.txt', '889.txt', '89.txt', '890.txt', '891.txt', '892.txt', '893.txt', '894.txt', '895.txt', '896.txt', '897.txt', '898.txt', '899.txt', '9.txt', '90.txt', '900.txt', '901.txt', '902.txt', '903.txt', '904.txt', '905.txt', '906.txt', '907.txt', '908.txt', '909.txt', '91.txt', '910.txt', '911.txt', '912.txt', '913.txt', '914.txt', '915.txt', '916.txt', '917.txt', '918.txt', '919.txt', '92.txt', '920.txt', '921.txt', '922.txt', '923.txt', '924.txt', '925.txt', '926.txt', '927.txt', '928.txt', '929.txt', '93.txt', '930.txt', '931.txt', '932.txt', '933.txt', '934.txt', '935.txt', '936.txt', '937.txt', '938.txt', '939.txt', '94.txt', '940.txt', '941.txt', '942.txt', '943.txt', '944.txt', '945.txt', '946.txt', '947.txt', '948.txt', '949.txt', '95.txt', '950.txt', '951.txt', '952.txt', '953.txt', '954.txt', '955.txt', '956.txt', '957.txt', '958.txt', '959.txt', '96.txt', '960.txt', '961.txt', '962.txt', '963.txt', '964.txt', '965.txt', '966.txt', '967.txt', '968.txt', '969.txt', '97.txt', '970.txt', '971.txt', '972.txt', '973.txt', '974.txt', '975.txt', '976.txt', '977.txt', '978.txt', '979.txt', '98.txt', '980.txt', '981.txt', '982.txt', '983.txt', '984.txt', '985.txt', '986.txt', '987.txt', '988.txt', '989.txt', '99.txt', '990.txt', '991.txt', '992.txt', '993.txt', '994.txt', '995.txt', '996.txt', '997.txt', '998.txt', '999.txt']\n",
      "['sonnet17.xml', 'sonnet18.xml']\n",
      "['.DS_Store', '125.xml', '126.xml', '127.xml', '128.xml', '129.xml', '130.xml', '131.xml', '132.xml', '133.xml', '134.xml', '135.xml', '136.xml', '137.xml', '138.xml', '139.xml', '140.xml', '141.xml', '142.xml', '143.xml', '144.xml', '145.xml', '146.xml', '147.xml', '148.xml', '149.xml', '150.xml', '151.xml', '152.xml', '153.xml', '154.xml', '155.xml', '156.xml', '157.xml', '158.xml', '159.xml', '160.xml', '161.xml', '162.xml', '163.xml', '164.xml', '165.xml', '166.xml', '167.xml', '168.xml', '169.xml', '170.xml', '171.xml', '172.xml', '173.xml', '174.xml', '175.xml', '176.xml', '177.xml', '178.xml', '179.xml', '180.xml', '181.xml', '182.xml', '183.xml', '184.xml', '185.xml', '302.xml', '690.xml']\n"
     ]
    }
   ],
   "source": [
    "for root, directory, filename in os.walk(\"data\"):\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, `os.walk()` allows you to efficiently loop over the entire tree. As always, don't forget that help is right around the corner in your notebooks. Using `help()`, you can quickly access the documentation of modules (but only after you have imported them!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function walk in module os:\n",
      "\n",
      "walk(top, topdown=True, onerror=None, followlinks=False)\n",
      "    Directory tree generator.\n",
      "    \n",
      "    For each directory in the directory tree rooted at top (including top\n",
      "    itself, but excluding '.' and '..'), yields a 3-tuple\n",
      "    \n",
      "        dirpath, dirnames, filenames\n",
      "    \n",
      "    dirpath is a string, the path to the directory.  dirnames is a list of\n",
      "    the names of the subdirectories in dirpath (excluding '.' and '..').\n",
      "    filenames is a list of the names of the non-directory files in dirpath.\n",
      "    Note that the names in the lists are just names, with no path components.\n",
      "    To get a full path (which begins with top) to a file or directory in\n",
      "    dirpath, do os.path.join(dirpath, name).\n",
      "    \n",
      "    If optional arg 'topdown' is true or not specified, the triple for a\n",
      "    directory is generated before the triples for any of its subdirectories\n",
      "    (directories are generated top down).  If topdown is false, the triple\n",
      "    for a directory is generated after the triples for all of its\n",
      "    subdirectories (directories are generated bottom up).\n",
      "    \n",
      "    When topdown is true, the caller can modify the dirnames list in-place\n",
      "    (e.g., via del or slice assignment), and walk will only recurse into the\n",
      "    subdirectories whose names remain in dirnames; this can be used to prune the\n",
      "    search, or to impose a specific order of visiting.  Modifying dirnames when\n",
      "    topdown is false is ineffective, since the directories in dirnames have\n",
      "    already been generated by the time dirnames itself is generated. No matter\n",
      "    the value of topdown, the list of subdirectories is retrieved before the\n",
      "    tuples for the directory and its subdirectories are generated.\n",
      "    \n",
      "    By default errors from the os.listdir() call are ignored.  If\n",
      "    optional arg 'onerror' is specified, it should be a function; it\n",
      "    will be called with one argument, an OSError instance.  It can\n",
      "    report the error to continue with the walk, or raise the exception\n",
      "    to abort the walk.  Note that the filename is available as the\n",
      "    filename attribute of the exception object.\n",
      "    \n",
      "    By default, os.walk does not follow symbolic links to subdirectories on\n",
      "    systems that support them.  In order to get this functionality, set the\n",
      "    optional argument 'followlinks' to true.\n",
      "    \n",
      "    Caution:  if you pass a relative pathname for top, don't change the\n",
      "    current working directory between resumptions of walk.  walk never\n",
      "    changes the current directory, and assumes that the client doesn't\n",
      "    either.\n",
      "    \n",
      "    Example:\n",
      "    \n",
      "    import os\n",
      "    from os.path import join, getsize\n",
      "    for root, dirs, files in os.walk('python/Lib/email'):\n",
      "        print(root, \"consumes\", end=\"\")\n",
      "        print(sum([getsize(join(root, name)) for name in files]), end=\"\")\n",
      "        print(\"bytes in\", len(files), \"non-directory files\")\n",
      "        if 'CVS' in dirs:\n",
      "            dirs.remove('CVS')  # don't visit CVS directories\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(os.walk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz\n",
    "\n",
    "In the next part of this chapter, we will need a way to sort our stories from the first, to the very last night. For our own convenience we will use a little hack for this. In this quiz, we would like you to create a new folder under `data` directory, called '1001'. You should copy all the original files from `arabian_nights` to this new folder, but give the files a new name, prepending zeros to filename until all nights have four digits in their name. `1001.txt` stays `1001.txt`, for instance, but `66.txt` becomes `0066.txt` and `2.txt` becomes `0002.txt` etc. This will make sorting the nights easier below. For this quiz you could for instance use a for loop in combination with a while loop (but don't get stuck in endless loops...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Parsing files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter we will introduce you to the task of text analysis in Python. You will learn how to read an entire corpus into Python, clean it and how to perform certain data analyses on those texts. We will also briefly introduce you to using Python's plotting library *matplotlib*, with which you can visualize your data.\n",
    "\n",
    "Before we delve into the main subject of this chapter, text analysis, we will first write a couple of utility functions that build upon the things you learnt in the previous chapter. Often we don't work with a single text file stored at our computer, but with multiple text files or entire corpora. We would like to have a way to load a corpus into Python.\n",
    "\n",
    "Remember how to read files? Each time we had to open a file, read the contents and then close the file. Since this is a series of steps we will often need to do, we can write a single function that does all that for us. We write a small utility function `read_file(filename)` that reads the specified file and simply returns all contents as a single string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    \"Read the contents of FILENAME and return as a string.\"\n",
    "    infile = open(filename) # windows users should use codecs.open after importing codecs\n",
    "    contents = infile.read()\n",
    "    infile.close()\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instead of having to open a file, read the contents and close the file, we can just call the function `read_file` to do all that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emma by Jane Austen 1816\n",
      "\n",
      "VOLUME I\n",
      "\n",
      "CHAPTER I\n",
      "\n",
      "\n",
      "Emma Woodhouse, handsome, clever, and rich, with a comfortable home\n",
      "and happy disposition, seemed to unite some of the best blessings\n",
      "of existence; and had lived nearly twenty-one years in the world\n",
      "with very little to distress or vex her.\n",
      "\n",
      "She was the youngest of the two daughters of a most affectionate,\n",
      "indulgent father; and had, in consequence of her sister's marriage,\n",
      "been mistress of his house from a very early period.  Her mother\n",
      "had died too long ago for her to have more than an indistinct\n",
      "remembrance of her caresses; and her place had been supplied\n",
      "by an excellent woman as governess, who had fallen little short\n",
      "of a mother in affection.\n"
     ]
    }
   ],
   "source": [
    "text = read_file(\"data/austen-emma-excerpt.txt\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the directory `data/gutenberg/training` we have a corpus consisting of multiple files with the extension `.txt`. This corpus is a collection of English novels which we downloaded for you from the [Gutenberg](http://www.gutenberg.org) project. We want to iterate over all these files. You can do this using the `listdir` function from the `os` module. We import this function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os import listdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, the `listdir` function is available to use. This function takes as argument the path to a directory and returns all the files and subdirectories present in that directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " 'arabian_nights',\n",
       " 'austen-emma-excerpt-tokenised.txt',\n",
       " 'austen-emma-excerpt.txt',\n",
       " 'austen-emma.txt',\n",
       " 'british-novels',\n",
       " 'gutenberg',\n",
       " 'haggard',\n",
       " 'names',\n",
       " 'twitter.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listdir(\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `listdir` returns a list and we can iterate over that list. Now, consider the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def list_textfiles(directory):\n",
    "    \"Return a list of filenames ending in '.txt' in DIRECTORY.\"\n",
    "    textfiles = []\n",
    "    for filename in listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            textfiles.append(directory + \"/\" + filename)\n",
    "    return textfiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `listdir` takes as argument the name of a directory and lists all filenames in that directory. We iterate over this list and append each filename that ends with the extension, `.txt` to a new list of `textfiles`. Using the `list_textfiles` function, the following code will read all text files in the directory `data/gutenberg/training` and outputs the length (in characters) of each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/gutenberg/training/austen-emma.txt has 887071 characters.\n",
      "data/gutenberg/training/austen-pride.txt has 684765 characters.\n",
      "data/gutenberg/training/austen-sense.txt has 673022 characters.\n",
      "data/gutenberg/training/blake-poems.txt has 38153 characters.\n",
      "data/gutenberg/training/blake-songs.txt has 32223 characters.\n",
      "data/gutenberg/training/bryant-stories.txt has 243901 characters.\n",
      "data/gutenberg/training/burgess-busterbrown.txt has 82992 characters.\n",
      "data/gutenberg/training/carroll-alice.txt has 144395 characters.\n",
      "data/gutenberg/training/chesterton-ball.txt has 457450 characters.\n",
      "data/gutenberg/training/chesterton-thursday.txt has 320525 characters.\n",
      "data/gutenberg/training/edgeworth-parents.txt has 916861 characters.\n",
      "data/gutenberg/training/melville-piazza.txt has 467970 characters.\n",
      "data/gutenberg/training/milton-paradise.txt has 468220 characters.\n",
      "data/gutenberg/training/shakespeare-caesar.txt has 112310 characters.\n",
      "data/gutenberg/training/shakespeare-hamlet.txt has 162881 characters.\n",
      "data/gutenberg/training/whitman-leaves.txt has 711215 characters.\n",
      "data/gutenberg/training/whitman-patriotic.txt has 174241 characters.\n",
      "data/gutenberg/training/whitman-poems.txt has 395130 characters.\n"
     ]
    }
   ],
   "source": [
    "for filepath in list_textfiles(\"data/gutenberg/training\"):\n",
    "    text = read_file(filepath)\n",
    "    print(filepath +  \" has \" + str(len(text)) + \" characters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous chapter we wrote a function to tokenize or split a text string into a list of words. However, using this function we lose information about where sentences end and start in the text. We will develop a function `split_sentences` that performs some very simple sentence splitting when passed a text string. Each sentence will be represented as a new string, so the function as a whole returns a list of sentence strings. We assume that any occurrence of either `.` or `!` or `?` marks the end of a sentence. In reality, this is more ambiguous of course. Consider for example the use of periods as end-of-sentence marker as well as in abbreviations and initials!\n",
    "\n",
    "How should we tackle this problem? Have a look at the following picture:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![caption](files/images/indexing.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first sentence *Hello there!* spans from index 0 to index 11. The second sentence from 13 to 26. If we come up with a way to extract those indexes, we could slice the text into separate sentences. First we define a utility function `end_of_sentence` that takes as argument a character and returns `True` if it is an end-of-sentence marker, otherwise it returns `False`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quiz!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the function `end_of_sentence_marker` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def end_of_sentence_marker(character):\n",
    "    # insert your code here\n",
    "    \n",
    "\n",
    "# these tests should return True if your code is correct\n",
    "print(end_of_sentence_marker(\"?\") == True)\n",
    "print(end_of_sentence_marker(\"a\") == False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important function we will use is the built in `enumerate`. `enumerate` takes as argument any iterable (a string a list etc.). Let's see it in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for element in enumerate(\"Python\"):\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, enumerate allows you to iterate over an iterable and for each element in that iterable, it gives you its corresponding index. A slightly more convenient way of iterating over `enumerate` is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for index, character in enumerate(\"Python\"):\n",
    "    print(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way, we have easy access to both the index and the original item in the iterable. Now we know enough to write our `split_sentences` function. We will walk you through it, step by step, but first try to read the function and think about what it possibly does at each step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_sentences(text):\n",
    "    \"Split a text string into a list of sentences.\"\n",
    "    sentences = []\n",
    "    start = 0\n",
    "    for end, character in enumerate(text):\n",
    "        if end_of_sentence_marker(character):\n",
    "            sentence = text[start: end + 1]\n",
    "            sentences.append(sentence)\n",
    "            start = end + 1\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `split_sentences` takes as argument a text represented by a simple string. Within the function we define a variable `sentences` in which we will store the individual sentences. We need to extract both the start position and the end position of each sentence. We know that the first sentence will always start at position 0. Therefore we define a variable start and set it to zero.\n",
    "\n",
    "Next we will use `enumerate` to loop over all individual characters in the text. Remember that enumerate returns pairs of indexes and their corresponding elements (here characters). For each character we check whether it is an end-of-sentence marker. If it is, the variable `end` marks the position in `text` where a sentence ends. We can now slice the text from the starting position to the end position and obtain our sentence. Notice that we add 1 to the end position. Why would that be? This is because, as you might remember from the first chapter, slices are non-inclusive, so `text[start:end]` would return the text starting at `start` and ending one position before `end`. Since we have reached the end of a sentence, we know that the next sentence will start at least one position later than our last end point. Therefore, we update the start variable to `end + 1`. Let's check whether our function works as promised:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(split_sentences(\"This is a sentence. Should we seperate it from this one?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quiz!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conclude this section, you will write a wrapper function `tokenize`, that takes as input a text represented by a string and tokenizes this string into sentences. After that, we clean each sentence, by lowercasing all words and removing punctuation. The final step is to tokenize each sentence into a list of words. The file `preprocessing.py` contains a function called `clean_text` which removes all punctuation from a text and turns all characters to lowercase. We import that function using the following line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyhum.preprocessing import clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"Transform TEXT into a list of sentences. Lowercase \n",
    "    each sentence and remove all punctuation. Finally split each\n",
    "    sentence into a list of words.\"\"\"\n",
    "    # insert your code here\n",
    "\n",
    "# these tests should return True if your code is correct\n",
    "print(tokenize(\"This is a sentence. So, what!\") == \n",
    "      [[\"this\", \"is\", \"a\", \"sentence\"], [\"so\", \"what\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Text Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> When the next night came, Dinarazad said to her sister Shahrazad: ‘In God’s name, sister, if you are not asleep, then tell us one of your stories!’ Shahrazad answered: ‘With great pleasure! I have heard tell, honoured King, that…’"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quiz!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the directory `data/arabian_nights` you will find 999 files. This is because in Burton's translation some nights are missing. The name of the file represents the corresponding night of storytelling in *Alf Laylah Wa Laylah*. Go have a look. Use the tokenize function and the corpus reading function we have defined above and tokenize and clean each night. Store the result in the variable named `corpus`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great job! You now should have a corpus containing 999 texts. It is always important to check whether our code actually produces the desired results. Let's check whether we indeed have 999 texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, that seems to be correct. It would be convenient for further processing to have the corpus in chronological order. Let's have a look the first 20 files returned by `list_textfiles`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_textfiles(\"data/arabian_nights\")[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the files are sorted by their string name and not by their numbering. To be able to sort the files by their numbers we must first remove the extension `.txt` as well as the directory `data/arabian_nights/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quiz!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1)** Write a function `remove_txt` that takes as argument a string and some extension that you want to remove. It should return the string without the extension. Tip: use the function `splitext` from the `os.path` module. Look up the documentation [here](http://docs.python.org/3.3/library/os.path.html#os.path.splitext)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os.path import splitext\n",
    "\n",
    "def remove_ext(filename):\n",
    "    # insert your code here\n",
    "    \n",
    "# these tests should return True if your code is correct\n",
    "print(remove_ext(\"data/arabian_nights/1.txt\") == \"data/arabian_nights/1\")\n",
    "print(remove_ext(\"ridiculous_selfie.jpg\") == \"ridiculous_selfie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2)** Write a function `remove_dir` that takes as argument a filepath and removes the directory from a filepath. Tip: use the function `basename` from the `os.path` module. Look up the document [here](http://docs.python.org/3.3/library/os.path.html#os.path.basename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os.path import basename\n",
    "\n",
    "def remove_dir(filepath):\n",
    "    # insert your code here\n",
    "    \n",
    "# these tests should return True if your code is correct\n",
    "print(remove_dir(\"data/arabian_nights/1.txt\") == \"1.txt\")\n",
    "print(remove_dir(\"/a/kind/of/funny/filepath/to/file.txt\") == \"file.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3)** Combine the two functions `remove_ext` and `remove_dir` into one function `get_filename`. This function takes as argument a filepath and returns the name (without the extensions) of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_filename(filepath):\n",
    "    # insert your code here\n",
    "    \n",
    "# these tests should return True if your code is correct\n",
    "print(get_filename(\"data/arabian_nights/1.txt\") == '1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step is to convert numbers represented as string (e.g. \"1\" and \"10\") to a number. This can be achieved by using the function `int`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_as_string = \"1\"\n",
    "x_as_int = int(x_as_string)\n",
    "print(x_as_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of converting a string into an integer, is called *type casting*. Strings are different types than integers. To see this, have a look at the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = \"1\"\n",
    "y = \"2\"\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12? Yes, 12. This is because, as you might remember from the first chapter, we can use the `+` operator to concatenate two strings. If we apply the same operation to integers, as in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = 1\n",
    "y = 2\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we get the expected result of 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quiz!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the functions `int` and `get_filename` into the function `get_night` to obtain the integer corresponding to a night."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_night(filepath):\n",
    "    # insert your code here\n",
    "\n",
    "# these tests should return True if your code is correct\n",
    "print(get_night(\"data/arabian_nights/1.txt\") == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so now we can convert the filepaths to integers corresponding to the nights of storytelling. But how will we use that to sort the corpus in chronological order? In chapter 1 we briefly discussed how to sort your collection of good reads. In combination with our `get_night` function, we can use `sort` to obtain a nicely chronologically ordered list of stories. Prepare yourself for some real Python magic, because the following lines of code might be a little dazzling...\n",
    "\n",
    "First we list all files using `list_textfiles` and store it in the variable `filenames`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filenames = list_textfiles('data/arabian_nights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we call the function `.sort()` on this list and supply as keyword our function `get_night`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filenames.sort(key=get_night)\n",
    "filenames[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we now have a perfectly chronologically ordered list of filenames. But how, **HOW!** did that work? As you might have guessed, the argument of `sort`: `key=get_night`, has something to do with all this magic. Without this argument, Python would just sort the filenames alphabeticaly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filenames = list_textfiles('data/arabian_nights')\n",
    "filenames.sort()\n",
    "print(filenames[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if we supply a function to `key`, Python will internally first apply that function to all items we want to sort. In our case this means Python converts all filepaths to integers. After that Python sorts the list. Then for each converted item it returns the corresponding item in the original list. (Technically this is not an accurate description, but it basically comes down to this.)\n",
    "\n",
    "If you still feel a little dizzy after all this, don't be afraid. Sometimes it is good enough to use a particular piece of code even if you don't completely understand it. We can now use these functions to reload the corpus, this time in chronological order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = []\n",
    "filenames = list_textfiles(\"data/arabian_nights\")\n",
    "filenames.sort(key=get_night)\n",
    "for filename in filenames:\n",
    "    text = read_file(filename)\n",
    "    corpus.append(tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first exploratory data analysis, we are going to compute for each night how many sentences it contains and how many words. It is quite easy to count the number of sentences per night, since each night is represented by a list of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences_per_night = []\n",
    "for night in corpus:\n",
    "    sentences_per_night.append(len(night))\n",
    "print(sentences_per_night[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the function `max` we can find out what the highest number of sentences is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max(sentences_per_night)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, if we would like to now what the lowest number of sentences is, we use the function `min`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min(sentences_per_night)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quiz!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `sum` takes a list of numbers as input and returns the sum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sum([1, 3, 3, 4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this function to compute the average number of sentences per night. Note if you use Python 2.7, you will need to convert the result of sum, which will be an integer to a `float`, using `float(some_number)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# if you use Python 3.x, both print statements will return \n",
    "# the same thing and you don't need to worry.\n",
    "number = 1\n",
    "print(number)\n",
    "number = float(number)\n",
    "print(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given our data structure of a list of sentences which are themselves lists of words, it is a little trickier to count for each night how many words it contains. One possible way is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words_per_night = []\n",
    "for night in corpus:\n",
    "    n_words = 0\n",
    "    for sentence in night:\n",
    "        n_words += len(sentence)\n",
    "    words_per_night.append(n_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you really understand these lines of code as you will need them in the next quiz. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The suspense created by Shahrazad’s story-telling skills is intriguing, especially the “cliff-hanger” ending each night which she uses to avert her own execution (and possibly that of womanhood). Every night she tells the Sultan a story only to stop at dawn and she picks up the thread the next night. But does it really take the whole night to tell a particular story?\n",
    "\n",
    "I am not aware of any exact numbers about how many words people speak per minute. Averages seem to fluctuate between 100 and 200 words per minute. Narrators are advised to use approximately 150 words per minute in audiobooks. I suspect that this number is a little lower for live storytelling and assume it lies around 130 words per minute (including pauses). Using this information, we can compute the time it takes to tell a particular story as follows:\n",
    "\n",
    "$$\\textrm{story time}(\\textrm{text}) = \\frac{\\textrm{number of words in text}}{\\textrm{number of words per minute}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quiz!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1)** Write a function called `story_time` that takes as input a text. Given a speed of 130 words per minute, compute how long it takes to tell that text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def story_time(text):\n",
    "    # insert your code here\n",
    "\n",
    "# these tests should return True if your code is correct\n",
    "print(story_time([[\"story\", \"story\"]]) * 130 == 2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2)** Compute the story_time for each night in our corpus. Assign the result to the variable `story_time_per_night`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "story_time_per_night = []\n",
    "# insert your code here\n",
    "print(story_time_per_night[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3**) Compute the average, minimum and maximum story telling time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing general statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have computed a range of general statistics for our corpus, it would be nice to visualize them. Python's plotting library *matplotlib* (see [here](http://matplotlib.org)) allows us to produce all kinds of graphs. We could for example, plot for each story, how many sentences it contains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(sentences_per_night)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quiz!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1)** Can you do the same for `words_per_night`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2)** And can you do the same for `story_time_per_night`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3)** In this final exercise we will put everything together what we have learnt so far. We want you to write a function `positions_of` that returns for a given word all sentence positions in the *Arabian Nights* where that word occurs. We are not interested in the positions relative to a particular night, but only to the corpus as a whole. Use that function to find all occurences of the name Sharahzad and store the corresponding indexes in the variable `positions_of_shahrazad`. Do the same thing for the name *Ali*. Store the result in `positions_of_ali`. Finally, find all occurences of *Egypt* and store the indexes in `positions_of_egypt`. Tip: (1) remember that we lowercased the entire corpus! (2) remember that indexes start at 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def positions_of(word):\n",
    "    #insert your code here\n",
    "\n",
    "positions_of_shahrazad = positions_of(\"shahrazad\")\n",
    "positions_of_ali = positions_of(\"ali\")\n",
    "positions_of_egypt = positions_of(\"egypt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything went well, the following lines of code should produce a nice dispersion plot of all sentence occurences of Shahrazad, Ali and Egypt in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "names = [\"Shahrazad\", \"Ali\", \"Egypt\"]\n",
    "plt.plot(positions_of_shahrazad, [1]*len(positions_of_shahrazad), \"|\", markersize=100)\n",
    "plt.plot(positions_of_ali, [2]*len(positions_of_ali), \"|\", markersize=100)\n",
    "plt.plot(positions_of_egypt, [0]*len(positions_of_egypt), \"|\", markersize=100)\n",
    "plt.yticks(range(len(names)), names)\n",
    "_ = plt.ylim(-1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Then Shahrazad reached the morning, and fell silent in the telling of her tale…"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignore the following, it's just here to make the page pretty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "/*\n",
       "Placeholder for custom user CSS\n",
       "\n",
       "mainly to be overridden in profile/static/custom/custom.css\n",
       "\n",
       "This will always be an empty file in IPython\n",
       "*/\n",
       "<style>\n",
       "    @import url(http://fonts.googleapis.com/css?family=Roboto:400,300,300italic,400italic,700,700italic);\n",
       "\n",
       "    div.cell{\n",
       "        font-family:'roboto','helvetica','sans';\n",
       "        color:#444;\n",
       "        width:800px;\n",
       "        margin-left:16% !important;\n",
       "        margin-right:auto;\n",
       "    }\n",
       "\n",
       "    div.text_cell_render{\n",
       "        font-family: 'roboto','helvetica','sans';\n",
       "        line-height: 145%;\n",
       "        font-size: 120%;\n",
       "        color:#444;\n",
       "        width:800px;\n",
       "        margin-left:auto;\n",
       "        margin-right:auto;\n",
       "    }\n",
       "    .CodeMirror{\n",
       "            font-family: \"Menlo\", source-code-pro,Consolas, monospace;\n",
       "    }\n",
       "    .prompt{\n",
       "        display: None;\n",
       "    }    \n",
       "    .warning{\n",
       "        color: rgb( 240, 20, 20 )\n",
       "        }  \n",
       "</style>\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML at 0x1057b3128>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"styles/custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><small><a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-sa/4.0/88x31.png\" /></a><br /><span xmlns:dct=\"http://purl.org/dc/terms/\" property=\"dct:title\">Python Programming for the Humanities</span> by <a xmlns:cc=\"http://creativecommons.org/ns#\" href=\"http://fbkarsdorp.github.io/python-course\" property=\"cc:attributionName\" rel=\"cc:attributionURL\">http://fbkarsdorp.github.io/python-course</a> is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Attribution-ShareAlike 4.0 International License</a>. Based on a work at <a xmlns:dct=\"http://purl.org/dc/terms/\" href=\"https://github.com/fbkarsdorp/python-course\" rel=\"dct:source\">https://github.com/fbkarsdorp/python-course</a>.</small></p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
